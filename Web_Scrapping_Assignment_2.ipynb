{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88306e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\anandraj\\anaconda3\\lib\\site-packages (4.4.3)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\anandraj\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\anandraj\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\anandraj\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\anandraj\\anaconda3\\lib\\site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\anandraj\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\anandraj\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\anandraj\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\anandraj\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\anandraj\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: idna in c:\\users\\anandraj\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: outcome in c:\\users\\anandraj\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\anandraj\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\anandraj\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\anandraj\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\anandraj\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e286934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3612e9",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. \n",
    "**you have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c2fe101",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\AnandRaj\\Downloads\\internship\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81889e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49fc08e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcd84772",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "665b1ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[6]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a1d32af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping job-title from the webpage\n",
    "job_title=[]\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')[0:10]:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "# Scrapping job location from the webpage\n",
    "job_location=[]\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]//span')[0:10]:\n",
    "    job_location.append(i.text)\n",
    "\n",
    "# Scrapping Company Name from the webpage\n",
    "company_name=[]\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')[0:10]:\n",
    "    company_name.append(i.text)\n",
    "\n",
    "# Scrapping Experience from the webpage\n",
    "experience_required=[]\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')[0:10]:\n",
    "    experience_required.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81f33411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contractual Hiring For Top MNC || Business Dat...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - Decision Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Jana Small Finance Bank</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Domlur)</td>\n",
       "      <td>KrazyBee</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Novel Office</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Women on career break_ Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad</td>\n",
       "      <td>Zinnov Management C</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BYJU'S DBEL : Sr Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>BYJUS</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SR. Data Analyst- SME- Pharma and Healthcare</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>CHRYSELYS</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>McAfee</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0  Contractual Hiring For Top MNC || Business Dat...   \n",
       "1                    Data Analyst - Decision Science   \n",
       "2                             Associate Data Analyst   \n",
       "3                             Associate Data Analyst   \n",
       "4                                Senior Data Analyst   \n",
       "5                                       Data Analyst   \n",
       "6                Women on career break_ Data Analyst   \n",
       "7                      BYJU'S DBEL : Sr Data Analyst   \n",
       "8       SR. Data Analyst- SME- Pharma and Healthcare   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                        Job_Location             Company_Name  \\\n",
       "0                                Bangalore/Bengaluru                TeamLease   \n",
       "1                                Bangalore/Bengaluru  Jana Small Finance Bank   \n",
       "2                                Bangalore/Bengaluru                    Optum   \n",
       "3                                Bangalore/Bengaluru                    Optum   \n",
       "4                        Bangalore/Bengaluru(Domlur)                 KrazyBee   \n",
       "5                                Bangalore/Bengaluru             Novel Office   \n",
       "6        Bangalore/Bengaluru, Hyderabad/Secunderabad      Zinnov Management C   \n",
       "7                                Bangalore/Bengaluru                    BYJUS   \n",
       "8  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...                CHRYSELYS   \n",
       "9                                 (WFH during Covid)                   McAfee   \n",
       "\n",
       "  Experience_required  \n",
       "0             5-8 Yrs  \n",
       "1             3-8 Yrs  \n",
       "2             2-7 Yrs  \n",
       "3             1-4 Yrs  \n",
       "4             3-5 Yrs  \n",
       "5             0-3 Yrs  \n",
       "6            5-10 Yrs  \n",
       "7             3-7 Yrs  \n",
       "8             2-6 Yrs  \n",
       "9             2-7 Yrs  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting scrapped data into DataFrame\n",
    "df=pd.DataFrame({'Job_Title':job_title,'Job_Location':job_location,'Company_Name':company_name,'Experience_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb21c7",
   "metadata": {},
   "source": [
    "# Q2 : Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. \n",
    "**You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "687457ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time \n",
    "driver = webdriver.Chrome(r\"C:\\Users\\AnandRaj\\Downloads\\internship\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90113a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16a74190",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc913693",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48991f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[6]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a04380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping job-title from the webpage\n",
    "job_title=[]\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')[0:10]:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "# Scrapping job location from the webpage\n",
    "job_location=[]\n",
    "for j in driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]//span')[0:10]:\n",
    "    job_location.append(j.text)\n",
    "\n",
    "# Scrapping Company Name from the webpage\n",
    "company_name=[]\n",
    "for k in driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')[0:10]:\n",
    "    company_name.append(k.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e559f97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Company_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Opportunity on Data Science_ Python with T...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - A.P. Maersk</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Maersk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>Infosys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infosys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>United Phosphorus Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>United Phosphorus Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>United Phosphorus Limited</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0  Job Opportunity on Data Science_ Python with T...   \n",
       "1                   Assistant Manager - Data Science   \n",
       "2                   Analystics & Modeling Specialist   \n",
       "3  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "4                       Data Scientist - A.P. Maersk   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job_Location  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "1                  Bangalore/Bengaluru, Mumbai, Pune   \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "3  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                 (WFH during Covid)   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                  Company_Name  \n",
       "0                                Tech Mahindra  \n",
       "1                                   CitiusTech  \n",
       "2                                    Accenture  \n",
       "3  NTT DATA Business Solutions Private Limited  \n",
       "4                                       Maersk  \n",
       "5                                      Infosys  \n",
       "6                                      Infosys  \n",
       "7                    United Phosphorus Limited  \n",
       "8                    United Phosphorus Limited  \n",
       "9                    United Phosphorus Limited  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Job_Title':job_title,'Job_Location':job_location,'Company_Name':company_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad651c8",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage \n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d305316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time \n",
    "driver = webdriver.Chrome(r\"C:\\Users\\AnandRaj\\Downloads\\internship\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6893fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "547b2620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering \"Data Scientist\" in \"Skill, Designation, Companies\" field\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8952fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the Search button\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div[2]/div[1]/div/button/span\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7e457d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying location filter and selecting \"Delhi/NCR\" otion\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div[2]/div[1]/div/div/div[5]/div/div/div/input\")\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "043291e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying Salary filter and selecting \"3-6 lakhs\" otion\n",
    "salary=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[3]/label/p\")\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0348676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping job-title from the webpage\n",
    "jtitle=[]\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')[0:10]:\n",
    "    jtitle.append(i.text)\n",
    "    \n",
    "# Scrapping job-location from the webpage\n",
    "jloc=[]\n",
    "for j in driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]//span')[0:10]:\n",
    "    jloc.append(j.text)\n",
    "\n",
    "# Scrapping Company name from the webpage\n",
    "comp=[]\n",
    "for k in driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')[0:10]:\n",
    "    comp.append(k.text)\n",
    "    \n",
    "# Scrapping Experience required from the webpage\n",
    "exp=[]\n",
    "for l in  driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')[0:10]:\n",
    "    exp.append(l.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdcd746f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infosys</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>United Phosphorus Limited</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>United Phosphorus Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>United Phosphorus Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tcs Hiring For Data Scientist</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Associate - MSET Support Role QR</td>\n",
       "      <td>Japan, Mumbai</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist ( Analytics )</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>Atlassian</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Job_Title  \\\n",
       "0         Analystics & Modeling Specialist   \n",
       "1                           Data Scientist   \n",
       "2                           Data Scientist   \n",
       "3                           Data Scientist   \n",
       "4                           Data Scientist   \n",
       "5                        Lead ML Scientist   \n",
       "6            Tcs Hiring For Data Scientist   \n",
       "7  Senior Associate - MSET Support Role QR   \n",
       "8                           Data Scientist   \n",
       "9      Senior Data Scientist ( Analytics )   \n",
       "\n",
       "                                        Job_Location  \\\n",
       "0  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                        Mumbai, Bangalore/Bengaluru   \n",
       "6   Chennai, Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "7                                      Japan, Mumbai   \n",
       "8                         Noida, Bangalore/Bengaluru   \n",
       "9                                 (WFH during Covid)   \n",
       "\n",
       "                      Company_Name Experience required  \n",
       "0                        Accenture             6-8 Yrs  \n",
       "1                          Infosys             2-7 Yrs  \n",
       "2        United Phosphorus Limited             3-7 Yrs  \n",
       "3        United Phosphorus Limited             2-7 Yrs  \n",
       "4        United Phosphorus Limited             2-7 Yrs  \n",
       "5                Fractal Analytics            6-10 Yrs  \n",
       "6  TATA CONSULTANCY SERVICES (TCS)             3-8 Yrs  \n",
       "7                   Morgan Stanley             0-3 Yrs  \n",
       "8                            Paytm             1-2 Yrs  \n",
       "9                        Atlassian             5-9 Yrs  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting scrapped data into DataFrame\n",
    "df=pd.DataFrame({'Job_Title':jtitle,'Job_Location':jloc,'Company_Name':comp,'Experience required':exp})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c82c96",
   "metadata": {},
   "source": [
    "#  Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4499569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\AnandRaj\\Downloads\\internship\\chromedriver.exe\")\n",
    "\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67401fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "close=driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e9f373",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('Sunglasses')\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a21bd76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Brand detail from the webpage\n",
    "brand=[]\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]'):\n",
    "    brand.append(i.text)\n",
    "\n",
    "# Scrapping Product Description from the webpage\n",
    "pro1=[]\n",
    "for j in driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\"]'):\n",
    "    pro1.append(j.text)\n",
    "    \n",
    "pro2=[]\n",
    "for j in driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]'):\n",
    "    pro2.append(j.text)\n",
    "    \n",
    "pro_des=pro1+pro2\n",
    "\n",
    "# Scrapping Price from the webpage\n",
    "price=[]\n",
    "for k in driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]'):\n",
    "    price.append(k.text)\n",
    "\n",
    "# Scrapping Discount from the webpage\n",
    "dis=[]\n",
    "for l in driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]'):\n",
    "    dis.append(l.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1ce3b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹1,049</td>\n",
       "      <td>47% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (51)</td>\n",
       "      <td>₹1,533</td>\n",
       "      <td>23% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹265</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹298</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>₹195</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (50)</td>\n",
       "      <td>₹699</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹246</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (...</td>\n",
       "      <td>₹283</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (52)</td>\n",
       "      <td>₹699</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>UV Protection Oval Sunglasses (55)</td>\n",
       "      <td>₹459</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mi</td>\n",
       "      <td>Polarized Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>33% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (53)</td>\n",
       "      <td>₹267</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>Riding Glasses, Night Vision Spectacle Sunglas...</td>\n",
       "      <td>₹199</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Round Sun...</td>\n",
       "      <td>₹949</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹719</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹269</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Round Sun...</td>\n",
       "      <td>₹949</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "      <td>₹349</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Round Sunglasses (52)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>25% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹279</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹359</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (54)</td>\n",
       "      <td>₹299</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹1,169</td>\n",
       "      <td>10% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (52)</td>\n",
       "      <td>₹296</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sewell</td>\n",
       "      <td>Mirrored, Night Vision, UV Protection, Riding ...</td>\n",
       "      <td>₹265</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>Night Vision, UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹220</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹1,049</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹211</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Rectangul...</td>\n",
       "      <td>₹749</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Wayfarer ...</td>\n",
       "      <td>₹749</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Polarized, Riding Glasses Sports, Wrap-around ...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Lee Topper</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹219</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (51)</td>\n",
       "      <td>₹1,533</td>\n",
       "      <td>23% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Mirrored Aviator Sunglasses (55)</td>\n",
       "      <td>₹399</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹1,039</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                Product Description  \\\n",
       "0       VINCENT CHASE     Polarized, UV Protection Round Sunglasses (50)   \n",
       "1       VINCENT CHASE     Polarized, UV Protection Round Sunglasses (51)   \n",
       "2           New Specs   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "3            Fastrack   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "4            Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "5           Elligator                UV Protection Round Sunglasses (54)   \n",
       "6   SHAAH COLLECTIONS  UV Protection, Polarized, Mirrored Rectangular...   \n",
       "7       VINCENT CHASE          UV Protection Rectangular Sunglasses (50)   \n",
       "8              PIRASO              UV Protection Aviator Sunglasses (54)   \n",
       "9              SUNBEE  UV Protection, Polarized Wayfarer Sunglasses (...   \n",
       "10      VINCENT CHASE          UV Protection Rectangular Sunglasses (52)   \n",
       "11           Roadster                 UV Protection Oval Sunglasses (55)   \n",
       "12                 Mi           Polarized Aviator Sunglasses (Free Size)   \n",
       "13         PHENOMENAL         UV Protection Retro Square Sunglasses (53)   \n",
       "14           Fastrack       UV Protection Aviator Sunglasses (Free Size)   \n",
       "15     ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)   \n",
       "16         LIZA ANGEL  Riding Glasses, Night Vision Spectacle Sunglas...   \n",
       "17      VINCENT CHASE  by Lenskart Polarized, UV Protection Round Sun...   \n",
       "18           Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...   \n",
       "19     kingsunglasses  Mirrored, UV Protection Wayfarer Sunglasses (F...   \n",
       "20      VINCENT CHASE  by Lenskart Polarized, UV Protection Round Sun...   \n",
       "21     ROZZETTA CRAFT  UV Protection, Gradient Retro Square Sunglasse...   \n",
       "22           Fastrack                UV Protection Round Sunglasses (52)   \n",
       "23             PIRASO              UV Protection Aviator Sunglasses (54)   \n",
       "24             PIRASO              UV Protection Aviator Sunglasses (58)   \n",
       "25          Rich Club         UV Protection Retro Square Sunglasses (54)   \n",
       "26           Fastrack              UV Protection Aviator Sunglasses (58)   \n",
       "27             PIRASO          UV Protection Rectangular Sunglasses (52)   \n",
       "28             Sewell  Mirrored, Night Vision, UV Protection, Riding ...   \n",
       "29               SRPM  Night Vision, UV Protection Round Sunglasses (54)   \n",
       "30     ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...   \n",
       "31      VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...   \n",
       "32               SRPM             UV Protection Wayfarer Sunglasses (50)   \n",
       "33      VINCENT CHASE  by Lenskart Polarized, UV Protection Rectangul...   \n",
       "34      VINCENT CHASE  by Lenskart Polarized, UV Protection Wayfarer ...   \n",
       "35     ROZZETTA CRAFT  Polarized, Riding Glasses Sports, Wrap-around ...   \n",
       "36         Lee Topper   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "37      VINCENT CHASE     Polarized, UV Protection Round Sunglasses (51)   \n",
       "38          ROYAL SON                   Mirrored Aviator Sunglasses (55)   \n",
       "39           Fastrack              UV Protection Aviator Sunglasses (58)   \n",
       "\n",
       "     Price Discount  \n",
       "0   ₹1,049  47% off  \n",
       "1   ₹1,533  23% off  \n",
       "2     ₹265  86% off  \n",
       "3     ₹639  20% off  \n",
       "4     ₹799  20% off  \n",
       "5     ₹298  88% off  \n",
       "6     ₹195  88% off  \n",
       "7     ₹699  65% off  \n",
       "8     ₹246  84% off  \n",
       "9     ₹283  78% off  \n",
       "10    ₹699  65% off  \n",
       "11    ₹459  58% off  \n",
       "12    ₹799  33% off  \n",
       "13    ₹267  73% off  \n",
       "14    ₹639  20% off  \n",
       "15    ₹499  77% off  \n",
       "16    ₹199  80% off  \n",
       "17    ₹949  52% off  \n",
       "18    ₹719  20% off  \n",
       "19    ₹269  82% off  \n",
       "20    ₹949  52% off  \n",
       "21    ₹349  82% off  \n",
       "22    ₹599  25% off  \n",
       "23    ₹279  82% off  \n",
       "24    ₹359  86% off  \n",
       "25    ₹299  57% off  \n",
       "26  ₹1,169  10% off  \n",
       "27    ₹296  88% off  \n",
       "28    ₹265  82% off  \n",
       "29    ₹220  77% off  \n",
       "30    ₹449  77% off  \n",
       "31  ₹1,049  58% off  \n",
       "32    ₹211  83% off  \n",
       "33    ₹749  62% off  \n",
       "34    ₹749  70% off  \n",
       "35    ₹499  75% off  \n",
       "36    ₹219  78% off  \n",
       "37  ₹1,533  23% off  \n",
       "38    ₹399  73% off  \n",
       "39  ₹1,039  20% off  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting 1st page scrapped data into DataFrame\n",
    "df=pd.DataFrame({'Brand':brand,'Product Description':pro_des,'Price':price,'Discount':dis})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bfab397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹1,049</td>\n",
       "      <td>47% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (51)</td>\n",
       "      <td>₹1,533</td>\n",
       "      <td>23% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹265</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹288</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Retro Squar...</td>\n",
       "      <td>₹259</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>UV Protection Oval Sunglasses (55)</td>\n",
       "      <td>₹459</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (55)</td>\n",
       "      <td>₹279</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹216</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Name                                Product Description   Price  \\\n",
       "0    VINCENT CHASE     Polarized, UV Protection Round Sunglasses (50)  ₹1,049   \n",
       "1    VINCENT CHASE     Polarized, UV Protection Round Sunglasses (51)  ₹1,533   \n",
       "2        New Specs   UV Protection Rectangular Sunglasses (Free Size)    ₹265   \n",
       "3         Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ₹639   \n",
       "4         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹799   \n",
       "..             ...                                                ...     ...   \n",
       "95    Silver Kartz      UV Protection Wayfarer Sunglasses (Free Size)    ₹288   \n",
       "96          SUNBEE  UV Protection, Polarized, Mirrored Retro Squar...    ₹259   \n",
       "97        Roadster                 UV Protection Oval Sunglasses (55)    ₹459   \n",
       "98          PIRASO              UV Protection Aviator Sunglasses (55)    ₹279   \n",
       "99  kingsunglasses                UV Protection Round Sunglasses (54)    ₹216   \n",
       "\n",
       "   Discount  \n",
       "0   47% off  \n",
       "1   23% off  \n",
       "2   86% off  \n",
       "3   20% off  \n",
       "4   20% off  \n",
       "..      ...  \n",
       "95  80% off  \n",
       "96  80% off  \n",
       "97  58% off  \n",
       "98  82% off  \n",
       "99  80% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for scrapping data from next pages, defining Start & End of the page\n",
    "start= 0\n",
    "end= 3\n",
    "for page in range(start,end):\n",
    "    \n",
    "# Scrapping Brand detail from the next pages\n",
    "    for j in driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]'):\n",
    "        brand.append(j.text)\n",
    "    \n",
    "# Scrapping Product Description from the next pages\n",
    "    for k in driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\"]'):\n",
    "        pro1.append(k.text)\n",
    "        \n",
    "    for l in driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]'):\n",
    "        pro2.append(l.text)\n",
    "        \n",
    "    pro_des=pro1+pro2\n",
    "    \n",
    "# Scrapping Price from the next pages    \n",
    "    for m in driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]'):\n",
    "        price.append(m.text)\n",
    "    \n",
    "# Scrapping Discount from the next pages\n",
    "    for n in driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]'):\n",
    "        dis.append(n.text)  \n",
    "    \n",
    "    nxt_button=driver.find_elements(By.XPATH,\"//a[@class='ge-49M']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[page].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        print(\"Page not found\")\n",
    "\n",
    "# converting first 100 scrapped data into DataFrame\n",
    "df1=pd.DataFrame({'Brand Name':brand,'Product Description':pro_des, 'Price':price,'Discount':dis})\n",
    "df1.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca89f3",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "**As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9603f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\AnandRaj\\Downloads\\internship\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bae4516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-128-gb/product-reviews/itmf1f0a58f1ecd7?pid=MOBFWBYZK3HACR72&lid=LSTMOBFWBYZK3HACR72PX4KSA&mar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05174e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate1=[]\n",
    "rate2=[]\n",
    "summary=[]\n",
    "f_rev=[]\n",
    "\n",
    "# for scrapping data from different pages to get first 100 reviews, defining Start & End of the page\n",
    "start=0\n",
    "end=15\n",
    "for page in range(start,end):\n",
    "    \n",
    "# Scrapping rating from different pages \n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]'):\n",
    "        rate1.append(i.text)\n",
    "        \n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1rdVr6 _1BLPMq\"]'):\n",
    "        rate2.append(i.text)\n",
    "    rate=rate1+rate2\n",
    "\n",
    "# Scrapping Review Summary from different pages\n",
    "    for j in driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]'):\n",
    "        summary.append(j.text)\n",
    "        \n",
    "# Scrapping Full Review from different pages\n",
    "    for k in driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]'):\n",
    "        f_rev.append(k.text)\n",
    "        \n",
    "#scraping the list of reviews data from different pages\n",
    "    nxt_button=driver.find_elements(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href')) #getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "280ff2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Wow superb camera phone\\nVery smooth speed and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>The brand is very trustworthy and i got genuin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Awesome phone … value for money.. Happy with b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Guys ,this is just Beast at Every Aspect of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Thanx flipkart for value super sale for short ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Appreciated with product!!!!!! It's amazing🤩 w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Pretty good</td>\n",
       "      <td>Delivery is super fast, after using it for 2 w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Plz don't hesitate even a bit for ordering iph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>This iPhone 12 was replacing Android , so it w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>An absolute charm to have this phone in your h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating         Review Summary  \\\n",
       "0       5               Terrific   \n",
       "1       5       Perfect product!   \n",
       "2       5      Terrific purchase   \n",
       "3       5  Mind-blowing purchase   \n",
       "4       5     Highly recommended   \n",
       "..    ...                    ...   \n",
       "95      4                 Super!   \n",
       "96      5            Pretty good   \n",
       "97      5              Wonderful   \n",
       "98      5              Brilliant   \n",
       "99      4                Awesome   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Wow superb camera phone\\nVery smooth speed and...  \n",
       "1   The brand is very trustworthy and i got genuin...  \n",
       "2   Awesome phone … value for money.. Happy with b...  \n",
       "3   Guys ,this is just Beast at Every Aspect of Co...  \n",
       "4   Thanx flipkart for value super sale for short ...  \n",
       "..                                                ...  \n",
       "95  Appreciated with product!!!!!! It's amazing🤩 w...  \n",
       "96  Delivery is super fast, after using it for 2 w...  \n",
       "97  Plz don't hesitate even a bit for ordering iph...  \n",
       "98  This iPhone 12 was replacing Android , so it w...  \n",
       "99  An absolute charm to have this phone in your h...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting scrapped data for first 100 reviews into DataFrame\n",
    "review=pd.DataFrame({'Rating':rate,'Review Summary':summary,'Full Review':f_rev})\n",
    "review.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7920a2",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "159a4c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\AnandRaj\\Downloads\\internship\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7be17e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ecce0050",
   "metadata": {},
   "outputs": [],
   "source": [
    "close=driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6797b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering \"sneakers\" in \"search for products\" field\n",
    "product=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec2a7cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the Search button\n",
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6062dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#introducing list for brand, product description, price & discount\n",
    "brand=[]\n",
    "prod1=[]\n",
    "prod2=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "# for scrapping data from different pages to get first 100 reviews, defining Start & End of the page\n",
    "for page in range(0,3):\n",
    "    \n",
    "# Scrapping brand list from different pages \n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]'):\n",
    "        brand.append(i.text)\n",
    "        \n",
    "# Scrapping product description from different pages \n",
    "    for j in driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]'):\n",
    "        prod1.append(j.text)\n",
    "        \n",
    "    for c in driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\"]'):\n",
    "        prod2.append(c.text)\n",
    "    prod=prod1+prod2\n",
    "    \n",
    "# Scrapping price from different pages \n",
    "    for k in driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]'):\n",
    "        price.append(k.text)\n",
    "        \n",
    "# Scrapping discount from different pages \n",
    "    for l in driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]'):\n",
    "        discount.append(l.text)\n",
    "        \n",
    "#scraping the required data from different pages\n",
    "    nxt_button=driver.find_elements(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a0c06432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arivo</td>\n",
       "      <td>White sneaker Sneakers For Men</td>\n",
       "      <td>₹539</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹288</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹419</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Sparx</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹709</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Women White Pink Colourblocked Flatform Sneake...</td>\n",
       "      <td>₹2,557</td>\n",
       "      <td>43% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>HOTSTYLE</td>\n",
       "      <td>Skypy-31 Walking Shoes,Training Shoes,Sneakers...</td>\n",
       "      <td>₹292</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bretton</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹251</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Echor</td>\n",
       "      <td>WATERPROOF-05cFULLWHITE Sneakers For Men</td>\n",
       "      <td>₹599</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand                                Product Description   Price  \\\n",
       "0      Arivo                     White sneaker Sneakers For Men    ₹539   \n",
       "1         TR                                   Sneakers For Men    ₹399   \n",
       "2     Labbin                                   Sneakers For Men    ₹499   \n",
       "3       aadi                                   Sneakers For Men    ₹288   \n",
       "4   Magnolia                                   Sneakers For Men    ₹419   \n",
       "..       ...                                                ...     ...   \n",
       "95     Sparx                                   Sneakers For Men    ₹709   \n",
       "96      PUMA  Women White Pink Colourblocked Flatform Sneake...  ₹2,557   \n",
       "97  HOTSTYLE  Skypy-31 Walking Shoes,Training Shoes,Sneakers...    ₹292   \n",
       "98   Bretton                                   Sneakers For Men    ₹251   \n",
       "99     Echor           WATERPROOF-05cFULLWHITE Sneakers For Men    ₹599   \n",
       "\n",
       "   Discount  \n",
       "0   72% off  \n",
       "1   73% off  \n",
       "2   50% off  \n",
       "3   71% off  \n",
       "4   58% off  \n",
       "..      ...  \n",
       "95  15% off  \n",
       "96  43% off  \n",
       "97  70% off  \n",
       "98  74% off  \n",
       "99  40% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sneaker_data=pd.DataFrame({'Brand':brand,'Product Description':prod,'Price':price,'Discount':discount})\n",
    "Sneaker_data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9499f6fa",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes \n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6352cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time \n",
    "driver = webdriver.Chrome(r\"C:\\Users\\AnandRaj\\Downloads\\internship\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42e04879",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38d5412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_filter=driver.find_element(By.XPATH,\"//ul[@class='price-list']/li[2]/label/div\")\n",
    "price_filter.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "762c418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting required filter of colour black\n",
    "colour_filter=driver.find_element(By.XPATH,\"//span[@data-colorhex='black']\")\n",
    "colour_filter.text\n",
    "colour_filter.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72e3d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting required filter of price\n",
    "\n",
    "price_filter=driver.find_element(By.XPATH,\"//ul[@class='price-list']/li[2]/label/div\")\n",
    "price_filter.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ca11b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nike', 'Hush Puppies', 'Tommy Hilfiger', 'Nike', 'ADIDAS Originals', 'Skechers', 'ADIDAS Originals', 'Tommy Hilfiger', 'Nike', 'Nike', 'Nike', 'Nike', 'ADIDAS', 'Nike', 'PUMA Motorsport', 'Puma', 'Puma', 'ADIDAS', 'ROSSO BRUNELLO', 'ADIDAS', 'UNDER ARMOUR', 'Puma', 'Nike', 'ADIDAS', 'ADIDAS Originals', 'UNDER ARMOUR', 'Puma', 'Puma', 'ADIDAS Originals', 'Tommy Hilfiger', 'Nike', 'Tommy Hilfiger', 'Puma', 'Nike', 'Reebok', 'Puma', 'PUMA Hoops', 'Nike', 'ADIDAS', 'ALDO', 'Hush Puppies', 'ADIDAS Originals', 'ADIDAS Originals', 'Nike', 'Skechers', 'Skechers', 'Tommy Hilfiger', 'Puma', 'Nike', 'Hush Puppies']\n",
      "['Men ZOOM WINFLO8 Running Shoes', 'Men Solid Leather Formal Slip-Ons', 'Men Solid Sneakers', 'Lebron Witness VI Basketball', 'Men Leather Niteball Sneakers', 'Men Sports Shoes', 'Men ZX 22 BOOST Sneakers', 'Men Slip-On Sneakers', 'Men React Infinity 3 Running', 'Men Running Shoes', 'Men JORDAN LOW Basketball Shoe', 'Men SRG 3 FK Training Shoes', 'Men Entry Hiker 2.R.RDY Trek', 'Kyrie Flytrap 5 Basketball', 'Mercedes AMG Petronas F1 Shoes', 'Men Reverse Classics Sneakers', 'Eternity Nitro Running Shoes', 'Men Dropset Training Shoes', 'Men Textured Leather Loafers', 'Men Defiant Generation Tennis', 'Men UA TriBase Reign4 Training', 'Men Liberate Running Shoes', 'Men Zoom C Pro HC Tennis Shoes', 'Men Solar Glide 4 ST Running', 'Men Solid Oznova Sneakers', 'Men HOVR Sonic SE Running Shoe', 'Unisex Wild Rider Sneakers', 'Men Nitro 2 WIDE Running Shoes', 'Men Ozrah Leather Sneakers', 'Men Leather Sneakers', 'Air Max Axis Sneakers', 'Men Leather Sneakers', 'Men Deviate Nitro Shoes', 'Women Running Shoes', 'Men Zig Dynamica2Adventure Run', 'Unisex Eliminate Pro II Shoes', 'Fives Blaze Court Basketball', 'Men REACT MILER 3 Running Shoe', 'Women Eastrail 2 Hiking Shoes', 'Men Leather Loafers', 'Men Perforations Leather Slip-On Sneakers', 'Men Retropy F90 Sneakers', 'Men Woven NMD_31 Sneakers', 'Women React Escape Running', 'Men Sports Shoes', 'Men Walking Shoes', 'Men Leather Sneakers', 'Men Velocity Nitro 2 Running', 'Men FREE RUN 2 Sneakers', 'Men Solid Leather Formal Slip-Ons']\n",
      "['Rs. 7880Rs. 8295', 'Rs. 7649Rs. 8999', 'Rs. 8999', 'Rs. 8295', 'Rs. 10799Rs. 11999', 'Rs. 8499', 'Rs. 10799Rs. 11999', 'Rs. 7999', 'Rs. 13295Rs. 13995', 'Rs. 7495', 'Rs. 12795', 'Rs. 8450Rs. 8895', 'Rs. 7649Rs. 8999', 'Rs. 8195', 'Rs. 9349Rs. 10999', 'Rs. 7199Rs. 8999', 'Rs. 12999', 'Rs. 12999', 'Rs. 12999', 'Rs. 7999Rs. 9999', 'Rs. 10199Rs. 11999', 'Rs. 8799Rs. 10999', 'Rs. 7560Rs. 8895', 'Rs. 9749Rs. 14999', 'Rs. 11999', 'Rs. 8499Rs. 9999', 'Rs. 7199Rs. 8999', 'Rs. 9599Rs. 11999', 'Rs. 11049Rs. 12999', 'Rs. 8299', 'Rs. 8355Rs. 8795', 'Rs. 7799', 'Rs. 10499Rs. 14999', 'Rs. 7880Rs. 8295', 'Rs. 8999', 'Rs. 7199Rs. 8999', 'Rs. 8249Rs. 10999', 'Rs. 10495', 'Rs. 7999', 'Rs. 7799Rs. 12999', 'Rs. 7999', 'Rs. 9999', 'Rs. 11199Rs. 13999', 'Rs. 9770Rs. 11495', 'Rs. 7999', 'Rs. 7999', 'Rs. 8299', 'Rs. 8799Rs. 10999', 'Rs. 9210Rs. 9695', 'Rs. 9999']\n"
     ]
    }
   ],
   "source": [
    "brand=[]\n",
    "s_s_desc=[]\n",
    "price=[]\n",
    "b_name=driver.find_elements(By.XPATH,\"//h3[@class='product-brand']\")\n",
    "desc=driver.find_elements(By.XPATH,\"//h4[@class='product-product']\")\n",
    "pr=driver.find_elements(By.XPATH,\"//div[@class='product-price']/span[1]\")\n",
    "#Using for loop with len function to iterate equal data\n",
    "for j in range(len(desc)):\n",
    "    brand.append(b_name[j].text)\n",
    "    s_s_desc.append(desc[j].text)\n",
    "    price.append(pr[j].text)\n",
    "print(brand)\n",
    "print(s_s_desc)\n",
    "print(price)\n",
    "\n",
    "#Clicking Next Button to reach next page to extract data\n",
    "n_button=driver.find_element(By.XPATH,\"//li[@class='pagination-next']/a\")\n",
    "n_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ad4250b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hush Puppies', 'ADIDAS', 'ADIDAS Originals', 'ADIDAS', 'Xtep', 'Bugatti', 'fitflop', 'Saint G', 'ALDO', 'Tommy Hilfiger', 'ADIDAS', 'Skechers', 'Puma', 'Skechers', 'Bugatti', 'Saint G', 'ADIDAS', 'ADIDAS Originals', 'ADIDAS', 'Puma', 'Geox', 'Geox', 'fitflop', 'UNDER ARMOUR', 'Saint G', 'Geox', 'Tommy Hilfiger', 'TOMS', 'Tommy Hilfiger', 'J.FONTINI', 'Tommy Hilfiger', 'Saint G', 'Clarks', 'Puma', 'Clarks', 'Skechers', 'Geox', 'Clarks', 'ALDO', 'Saint G', 'Geox', 'DAVINCHI', 'Hush Puppies', 'Saint G', 'Skechers', 'ALDO', 'Skechers', 'Tommy Hilfiger', 'Tommy Hilfiger', 'ROSSO BRUNELLO']\n",
      "['Men Solid Leather Formal Slip-Ons', 'Women Supernova Running Shoes', 'Men Woven Nmd_R1 Sneakers', 'Men Adizero Adios 7 Running', 'Men Skateboarding Shoes', 'Men Walking Shoes', 'Embellished Leather Flatform Sandals', 'Leather Rhinestone Decor Boots', 'Men Perforations Brogues Shoes', 'Women Leather Sneakers', 'Women SL20.3 Running Shoes', 'Men Go Run Hyper Burst Running', 'Unisex KING Pro 21 Football', 'Men Sports Shoes', 'Men Running Shoes', 'Leather Block', 'Women Adizero Adios 7 Run Shoe', 'Men Colorblocked Ozrah Sneaker', 'Women Super 3.0 Running Shoes', 'Women UltraRide Running Shoes', 'Men Textured Leather Driving Shoes', 'Men Leather Sneakers', 'Embellished Leather Wedge Sandals', 'Women Charged Vantage 2 Run', 'Leather Ankle Boots', 'Women Leather Heeled Boots', 'Men Leather Mid-Top Sneakers', 'Men Solid Sneakers', 'Men Solid Sneakers', 'Men Textured Leather Loafers', 'Men Leather Sneakers', 'Block Heeled Boots', 'Men Leather Slip-Ons', 'Women Magnify Nitro Running', 'Men Woven Design Suede Flat Boots', 'Men Woven Design Sneakers', 'Flatform Heels', 'Men Perforations Leather Derbys', 'Men Embossed Derby Formal Shoes', 'Leather Block Sandals', 'Women Textured Leather Loafers', 'Men Solid Leather Formal Loafers', 'Men Solid Formal Slip-Ons', 'Leather Block Sandals with Buckles', 'Women Printed Trekking Shoes', 'Women Ballerinas Flats', 'Women Arch Fit Slip-On Sneaker', 'Women Leather Kitten Sandals', 'Women Solid Slim Heel Sandals', 'Men Solid Leather Formal Derbys']\n",
      "['Rs. 9999', 'Rs. 9999', 'Rs. 12999', 'Rs. 9599Rs. 11999', 'Rs. 8599', 'Rs. 7499Rs. 9999', 'Rs. 8299', 'Rs. 13205Rs. 13900', 'Rs. 12999', 'Rs. 7599', 'Rs. 7799Rs. 11999', 'Rs. 8499', 'Rs. 8499Rs. 9999', 'Rs. 8499', 'Rs. 7499Rs. 9999', 'Rs. 9975Rs. 10500', 'Rs. 9599Rs. 11999', 'Rs. 11699Rs. 12999', 'Rs. 8999', 'Rs. 8999', 'Rs. 10990', 'Rs. 10990', 'Rs. 7499', 'Rs. 7199Rs. 7999', 'Rs. 9025Rs. 9500', 'Rs. 8999Rs. 17999', 'Rs. 10999', 'Rs. 8999', 'Rs. 9999', 'Rs. 8490', 'Rs. 8799', 'Rs. 7980Rs. 8400', 'Rs. 9999', 'Rs. 9099Rs. 12999', 'Rs. 9999', 'Rs. 7499', 'Rs. 11990', 'Rs. 7999', 'Rs. 9599Rs. 15999', 'Rs. 9810Rs. 10900', 'Rs. 9990', 'Rs. 8490', 'Rs. 9999', 'Rs. 8505Rs. 10500', 'Rs. 8999', 'Rs. 7999', 'Rs. 7999', 'Rs. 7199Rs. 7999', 'Rs. 7299', 'Rs. 8799Rs. 10999']\n"
     ]
    }
   ],
   "source": [
    "brand1=[]\n",
    "s_s_desc1=[]\n",
    "price1=[]\n",
    "br_name=driver.find_elements(By.XPATH,\"//h3[@class='product-brand']\")\n",
    "desc1=driver.find_elements(By.XPATH,\"//h4[@class='product-product']\")\n",
    "pr1=driver.find_elements(By.XPATH,\"//div[@class='product-price']/span[1]\")\n",
    "for j in range(len(br_name)):\n",
    "    brand1.append(br_name[j].text)\n",
    "    s_s_desc1.append(desc1[j].text)\n",
    "    price1.append(pr1[j].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88631fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands=brand+brand1\n",
    "s_s_describe=s_s_desc+s_s_desc1\n",
    "prices=price+price1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c663cedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Short Shoe Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men ZOOM WINFLO8 Running Shoes</td>\n",
       "      <td>Rs. 7880Rs. 8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 7649Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Men Solid Sneakers</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Lebron Witness VI Basketball</td>\n",
       "      <td>Rs. 8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Leather Niteball Sneakers</td>\n",
       "      <td>Rs. 10799Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Women Ballerinas Flats</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Women Arch Fit Slip-On Sneaker</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Women Leather Kitten Sandals</td>\n",
       "      <td>Rs. 7199Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Women Solid Slim Heel Sandals</td>\n",
       "      <td>Rs. 7299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROSSO BRUNELLO</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 8799Rs. 10999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand             Short Shoe Description               Price\n",
       "0               Nike     Men ZOOM WINFLO8 Running Shoes    Rs. 7880Rs. 8295\n",
       "1       Hush Puppies  Men Solid Leather Formal Slip-Ons    Rs. 7649Rs. 8999\n",
       "2     Tommy Hilfiger                 Men Solid Sneakers            Rs. 8999\n",
       "3               Nike       Lebron Witness VI Basketball            Rs. 8295\n",
       "4   ADIDAS Originals      Men Leather Niteball Sneakers  Rs. 10799Rs. 11999\n",
       "..               ...                                ...                 ...\n",
       "95              ALDO             Women Ballerinas Flats            Rs. 7999\n",
       "96          Skechers     Women Arch Fit Slip-On Sneaker            Rs. 7999\n",
       "97    Tommy Hilfiger       Women Leather Kitten Sandals    Rs. 7199Rs. 7999\n",
       "98    Tommy Hilfiger      Women Solid Slim Heel Sandals            Rs. 7299\n",
       "99    ROSSO BRUNELLO    Men Solid Leather Formal Derbys   Rs. 8799Rs. 10999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making DataFrame of the scrapped data\n",
    "df=pd.DataFrame(list(zip(brands[0:100],s_s_describe[0:100],prices[0:100])),columns=[\"Brand\",\"Short Shoe Description\",\"Price\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a4b9f8",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” \n",
    "You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4ce6e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\AnandRaj\\Downloads\\internship\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b63cfcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0406f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering \"Laptop\" in search field\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "search.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2db84a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on the search button\n",
    "search_button=driver.find_element(By.XPATH,'//div[@class=\"nav-search-submit nav-sprite\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e03615ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting CPU Type filter to “Intel Core i7” as required\n",
    "cpu_type=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/div[1]/span')\n",
    "cpu_type.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2d8580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping product title from the webpage\n",
    "title=[]\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"a-section a-spacing-none puis-padding-right-small s-title-instructions-style\"]')[0:10]:\n",
    "    title.append(i.text)\n",
    "    \n",
    "# Scrapping product price from the webpage\n",
    "price=[]\n",
    "for j in driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')[0:10]:\n",
    "    price.append(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f2aa065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sponsored\\nHP 15s- 11th Gen Intel Core i5 -8GB...</td>\n",
       "      <td>51,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sponsored\\nHP 15s, 11th Gen Intel Core i3, 8GB...</td>\n",
       "      <td>42,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Celeron N4020 15.6...</td>\n",
       "      <td>27,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) ...</td>\n",
       "      <td>25,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad Slim 1 Intel Celeron N4020 11.6...</td>\n",
       "      <td>21,288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo E41-55 AMD 14-inch (35.56cm) HD Thin an...</td>\n",
       "      <td>67,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS TUF Gaming A15, 15.6\" (39.62 cm) FHD 144H...</td>\n",
       "      <td>51,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dell New Inspiron 3525 Laptop, Intel Athlon Si...</td>\n",
       "      <td>43,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cm) HD...</td>\n",
       "      <td>79,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) Dell Latitude E5470 Intel Core i5 6t...</td>\n",
       "      <td>24,999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   Price\n",
       "0  Sponsored\\nHP 15s- 11th Gen Intel Core i5 -8GB...  51,890\n",
       "1  Sponsored\\nHP 15s, 11th Gen Intel Core i3, 8GB...  42,499\n",
       "2  Lenovo IdeaPad Slim 3 Intel Celeron N4020 15.6...  27,490\n",
       "3  ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) ...  25,490\n",
       "4  Lenovo IdeaPad Slim 1 Intel Celeron N4020 11.6...  21,288\n",
       "5  Lenovo E41-55 AMD 14-inch (35.56cm) HD Thin an...  67,000\n",
       "6  ASUS TUF Gaming A15, 15.6\" (39.62 cm) FHD 144H...  51,500\n",
       "7  Dell New Inspiron 3525 Laptop, Intel Athlon Si...  43,900\n",
       "8  ASUS VivoBook 14 (2021), 14-inch (35.56 cm) HD...  79,900\n",
       "9  (Renewed) Dell Latitude E5470 Intel Core i5 6t...  24,999"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Laptop=pd.DataFrame({'Title':title,'Price':price}) \n",
    "Laptop.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2378d231",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. \n",
    "You have to scrape company name, No. of days ago when job was posted, Rating of the company. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eb29bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\AnandRaj\\Downloads\\internship\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d00d126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f5b04fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs=driver.find_element(By.XPATH,'/html/body/div[1]/nav[2]/div/ul/li[5]/a')\n",
    "jobs.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "53024f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering \"Data Scientist\" in \"Skill, Designation, Companies\" field\n",
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input')\n",
    "search.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "176bbcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on location icon\n",
    "location=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]')\n",
    "location.click()\n",
    "\n",
    "# entering \"Noida\" for location search\n",
    "place=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "place.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "799da81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "958af817",
   "metadata": {},
   "outputs": [],
   "source": [
    "company=[]\n",
    "for i in driver.find_elements(By.XPATH,'//p[@class=\"company body-medium\"]'): #scrapping company name from page\n",
    "    company.append(i.text)\n",
    "\n",
    "# Scrapping No. of days ago when job was posted from the webpage\n",
    "day=[]\n",
    "for j in driver.find_elements(By.XPATH,'//span[@class=\"body-small-l\"]'):\n",
    "    day.append(j.text)\n",
    "del day[1:20:2] \n",
    "    \n",
    "# Scrapping Rating of the Company from the webpage\n",
    "rating=[]\n",
    "for k in driver.find_elements(By.XPATH,'//span[@class=\"body-small\"]'):\n",
    "    rating.append(k.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "319fa731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>No. of Days ago when job was posted</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBRE South Asia Pvt Ltd</td>\n",
       "      <td>26d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>19d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>21d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>29d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dew Solutions Pvt. Ltd.</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>One97 Communications Limited</td>\n",
       "      <td>12d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EY</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>15d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Company Name  \\\n",
       "0                   CBRE South Asia Pvt Ltd   \n",
       "1             GENPACT India Private Limited   \n",
       "2                                   Genpact   \n",
       "3  Ericsson India Global Services Pvt. Ltd.   \n",
       "4             GENPACT India Private Limited   \n",
       "5                   Dew Solutions Pvt. Ltd.   \n",
       "6  Ericsson India Global Services Pvt. Ltd.   \n",
       "7              One97 Communications Limited   \n",
       "8                                        EY   \n",
       "9              R Systems International Ltd.   \n",
       "\n",
       "  No. of Days ago when job was posted Rating  \n",
       "0                             26d ago    4.3  \n",
       "1                             19d ago    4.0  \n",
       "2                             21d ago    4.0  \n",
       "3                            1mon ago    4.3  \n",
       "4                             29d ago    4.0  \n",
       "5                              4d ago    4.3  \n",
       "6                            1mon ago    4.3  \n",
       "7                             12d ago    3.8  \n",
       "8                            1mon ago    3.8  \n",
       "9                             15d ago    3.7  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jobs=pd.DataFrame({'Company Name':company, 'No. of Days ago when job was posted':day, 'Rating':rating})\n",
    "Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69223d4",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2973d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\AnandRaj\\Downloads\\internship\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dc534c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6ee7a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting salary option\n",
    "salary=driver.find_element(By.XPATH,'/html/body/div[1]/nav[2]/div/ul/li[3]/a')\n",
    "salary.click()\n",
    "\n",
    "# selecting first option from drop down menu\n",
    "browser=driver.find_element(By.XPATH,'/html/body/div[1]/nav[2]/div/ul/li[3]/div/ul/li[1]/div/div[2]/p')\n",
    "browser.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ddf80068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enterring 'Data Scientist' in Search job profile\n",
    "job=driver.find_element(By.XPATH,'//input[@class=\"tt-input\"]')\n",
    "job.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1410e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting first option from drop down menu\n",
    "select=driver.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div/div')\n",
    "select.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7cd2adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping company name from the webpage\n",
    "comp=[]\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]/a'):\n",
    "    comp.append(i.text.split(\"\\n\"))\n",
    "    \n",
    "# merging sub lists into a single list and deleting even place items to get required data\n",
    "company=sum(comp,[])\n",
    "del company[1:20:2]\n",
    "\n",
    "# Scrapping total salary record from the webpage\n",
    "bsal=[]\n",
    "for a in driver.find_elements(By.XPATH,'//div[@class=\"sbold-list-header\"]/span'):\n",
    "    bsal.append(a.text.replace('(','').replace(')',''))\n",
    "\n",
    "# Scrapping Average salary from the webpage\n",
    "avgsal=[]\n",
    "for b in driver.find_elements(By.XPATH,'//p[@class=\"averageCtc\"]'): \n",
    "    avgsal.append(b.text)\n",
    "\n",
    "# Scrapping Minimum Salary & Maximum Salary from the webpage\n",
    "min_sal=[]\n",
    "max_sal=[]\n",
    "for c in driver.find_elements(By.XPATH,'//div[@class=\"value body-medium\"]'): \n",
    "    min_sal.append(c.text)\n",
    "    max_sal.append(c.text)\n",
    "del min_sal[1:20:2]\n",
    "del max_sal[0:20:2]\n",
    "\n",
    "# Scrapping Experience required data from the webpage\n",
    "exp=[]\n",
    "for d in driver.find_elements(By.XPATH,'//div[@class=\"sbold-list-header\"]'): \n",
    "    exp.append(d.text.split('('))\n",
    "    \n",
    "# merging sub lists into a single list and deleting even place items to get required data   \n",
    "req_exp=sum(exp,[]) \n",
    "del req_exp[1:20:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6ef82509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Total Salary Record</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 22 salaries</td>\n",
       "      <td>₹ 32.2L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 54 salaries</td>\n",
       "      <td>₹ 19.8L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 26.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 49 salaries</td>\n",
       "      <td>₹ 16.4L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 34 salaries</td>\n",
       "      <td>₹ 15.8L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>1-2 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 116 salaries</td>\n",
       "      <td>₹ 15.5L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 24.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 67 salaries</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sigmoid Analytics</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 19.7L</td>\n",
       "      <td>1 yr experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Legato Health Technologies</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>₹ 14.5L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tredence</td>\n",
       "      <td>based on 13 salaries</td>\n",
       "      <td>₹ 14.1L</td>\n",
       "      <td>₹ 8.8L</td>\n",
       "      <td>₹ 17.5L</td>\n",
       "      <td>3 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "      <td>4 yrs experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Company Name    Total Salary Record Average Salary  \\\n",
       "0                     Walmart   based on 22 salaries        ₹ 32.2L   \n",
       "1                    Ab Inbev   based on 54 salaries        ₹ 19.8L   \n",
       "2                       Optum   based on 49 salaries        ₹ 16.4L   \n",
       "3                          ZS   based on 34 salaries        ₹ 15.8L   \n",
       "4           Fractal Analytics  based on 116 salaries        ₹ 15.5L   \n",
       "5             Tiger Analytics   based on 67 salaries        ₹ 14.7L   \n",
       "6           Sigmoid Analytics   based on 10 salaries        ₹ 14.7L   \n",
       "7  Legato Health Technologies   based on 11 salaries        ₹ 14.5L   \n",
       "8                    Tredence   based on 13 salaries        ₹ 14.1L   \n",
       "9                        HSBC   based on 10 salaries        ₹ 14.0L   \n",
       "\n",
       "  Minimum Salary Maximum Salary  Experience Required  \n",
       "0        ₹ 25.0L        ₹ 45.0L  3-4 yrs experience   \n",
       "1        ₹ 15.0L        ₹ 26.0L  2-4 yrs experience   \n",
       "2        ₹ 11.0L        ₹ 22.6L  2-4 yrs experience   \n",
       "3        ₹ 11.0L        ₹ 22.0L  1-2 yrs experience   \n",
       "4         ₹ 9.0L        ₹ 24.0L  2-4 yrs experience   \n",
       "5         ₹ 9.0L        ₹ 20.0L  2-4 yrs experience   \n",
       "6        ₹ 12.7L        ₹ 19.7L     1 yr experience   \n",
       "7        ₹ 11.0L        ₹ 20.0L    4 yrs experience   \n",
       "8         ₹ 8.8L        ₹ 17.5L    3 yrs experience   \n",
       "9        ₹ 12.0L        ₹ 18.0L    4 yrs experience   "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Company Name':company,'Total Salary Record':bsal,'Average Salary':avgsal,'Minimum Salary':min_sal,'Maximum Salary':max_sal,'Experience Required':req_exp})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c41009e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
